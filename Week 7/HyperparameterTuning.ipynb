{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b42d5431",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "In de reeds besproken machine learning technieken hebben we reeds een aantal keer vermeld dat er hyperparameters (denk aan regularisatieparameters, manieren van regularisatie, kernel type, ...).\n",
    "\n",
    "In het geval van lineaire regressie gaat het dan over:\n",
    "* L1 of L2 norm\n",
    "* Regularisatieparameter $\\lambda$\n",
    "* learning rate\n",
    "\n",
    "In het geval van SVM over:\n",
    "* Type kernel\n",
    "* Regularisatieparameter C\n",
    "* Regularisatieparameter $\\gamma$\n",
    "\n",
    "Tot nu bestond de zoektocht naar de optimale combinatie van deze parameters door het manueel uitproberen en evalueren van een reeks combinaties van parameters.\n",
    "Deze methode is echter niet schaalbaar en kan geautomatiseerd worden.\n",
    "Dit gebeurd door middel van een gridsearch.\n",
    "\n",
    "## Gridsearch\n",
    "\n",
    "Het gridsearch algoritme bestaat eruit om een lijst op te stellen voor elke parameter welke waarden moeten getest worden.\n",
    "Voor elke mogelijke combinatie van parameters gaat er dan een model getrained en geevalueerd worden.\n",
    "Een voorbeeld van hoe dit kan geautomatiseerd worden binnen sklearn kan [hier](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) gevonden worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e64fc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 500 ms\n",
      "Wall time: 497 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cv': 3,\n",
       " 'error_score': nan,\n",
       " 'estimator__C': 1.0,\n",
       " 'estimator__break_ties': False,\n",
       " 'estimator__cache_size': 200,\n",
       " 'estimator__class_weight': None,\n",
       " 'estimator__coef0': 0.0,\n",
       " 'estimator__decision_function_shape': 'ovr',\n",
       " 'estimator__degree': 3,\n",
       " 'estimator__gamma': 'scale',\n",
       " 'estimator__kernel': 'rbf',\n",
       " 'estimator__max_iter': -1,\n",
       " 'estimator__probability': False,\n",
       " 'estimator__random_state': None,\n",
       " 'estimator__shrinking': True,\n",
       " 'estimator__tol': 0.001,\n",
       " 'estimator__verbose': False,\n",
       " 'estimator': SVC(),\n",
       " 'n_jobs': None,\n",
       " 'param_grid': {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
       "  'C': [0.1, 0.5, 0.9, 1, 1.5, 2, 10],\n",
       "  'gamma': [0.1, 0.5, 1]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': False,\n",
       " 'scoring': None,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "parameters = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'C': [0.1, 0.5, 0.9, 1, 1.5, 2, 10],\n",
    "    'gamma': [0.1,0.5,1]\n",
    "}\n",
    "\n",
    "svm = svm.SVC()   # Classifier met Support-vector machines\n",
    "gridsearch = GridSearchCV(svm, parameters, cv=3)\n",
    "\n",
    "%time gridsearch.fit(iris.data, iris.target)\n",
    "gridsearch.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c2b7c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 0.1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3488e5",
   "metadata": {},
   "source": [
    "De standaard methode van hierboven gaat alle combinaties afgaan.\n",
    "Andere methoden die sneller maar niet alle combinaties aftoetsen zijn\n",
    "* [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV)\n",
    "*[HalvingGridSearchCv](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV)\n",
    "*[HalvingRandomizedSearchCv](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV)\n",
    "\n",
    "Belangrijk om hierbij op te merken is dat het GridSearch algoritme enkel verschillende parameters van het model trained en dat er geen eigenschappen van de data kan veranderd worden.\n",
    "Indien je ook een exhausieve search wilt doen van het aantal hogere orde features of de vorm van scaling die gebruikt wordt op input parameters. Moet je een eigen wrapper schrijven die nog deze zaken uittest en de performantie van de uiteindelijke modellen vergelijkt.\n",
    "\n",
    "## Validatieset\n",
    "\n",
    "Welke data kunnen we nu gebruiken om deze gridsearch te evalueren.\n",
    "Zowel de testdata als de trainingsdata kan niet gebruikt worden omdat we niet kunnen evalueren op de data waarmee het model getrained is.\n",
    "Om deze reden wordt de dataset typisch in drie opgedeeld, namelijk een training-, test- en validatieset.\n",
    "De validatieset is de data die dan gebruikt kan worden voor hyperparameter tuning.\n",
    "Typisch wordt de dataset dan in de volgende groottes opgedeeld:\n",
    "* Testset: 15%\n",
    "* Validatieset: 15% \n",
    "* Trainingsdata: 70%\n",
    "\n",
    "Dit zijn echter geen vaste waarden en kunnen wat verschillen in de praktijk.\n",
    "Hoe meer data je beschibaar is hoe groter het percentage trainingsdata kan zijn. \n",
    "In het geval van big-data applicaties kan dit oplopen tot 98%.\n",
    "\n",
    "## K-fold cross validation\n",
    "\n",
    "Bij het steeds gebruiken van dezelfde validatieset is het mogelijk dat er een unieke split is die leidt tot een onverwacht goed of slecht resultaat.\n",
    "Om dit tegen te gaan kan er gebruik gemaakt worden van K-fold cross validation.\n",
    "Daarbij berekenen we de verwachte error K keer, elke keer met een andere train en validatie set om zo de kans te verhogen dat het uiteindelijke model ook goed werkt op de testset met ongeziene data.\n",
    "Standaard wordt er bij het gebruik van het gridsearch algoritme gebruik gemaakt van 5 folds voor het zoeken naar de beste hyperparameters.\n",
    "Indien de standaard manier niet voldoet voor de gewenste toepassing kan je ook de split rechtstreeks uitvoeren.\n",
    "Meer informatie over deze methode vind je [hier](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html)\n",
    "\n",
    "![kfold cross validation](images/kFold.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbfb555",
   "metadata": {},
   "source": [
    "## Oefening\n",
    "\n",
    "In [deze dataset](https://www.kaggle.com/mathchi/diabetes-data-set) is een hele reeks data beschikbaar over een aantal medische eigenschappen van personen en of deze personen diabetes hebben of niet.\n",
    "Ga nu op zoek naar het beste model om te voorspellen of een persoon diabetes gaat hebben of niet.\n",
    "Test hierbij zowel de logistische regressie en svm methoden en maak gebruik van gridsearch met 10-fold cross validation om de verschillende hyperparameters te testen. \n",
    "\n",
    "Wat is de hoogst behaalde accuraatheid en de benodigde hyperparameters?\n",
    "\n",
    "Indien dit gelukt is, zoek ook het model dat de hoogste weighted f1-score behaald. \n",
    "Welke techniek gebruikte dit model en welke hyperparameters zijn er hiervoor gekozen?\n",
    "Vergelijk beide modellen. Is er een significant verschil in de resulterende hyperparameters?\n",
    "Is de behaalde accuraatheid sterk afwijkend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebda46f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fb6f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#od.download(\"https://www.kaggle.com/mathchi/diabetes-data-set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca31b9be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./diabetes-data-set/diabetes.csv\")\n",
    "display(df.head())\n",
    "y = df.Outcome\n",
    "X = df.drop(\"Outcome\", axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09239695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3680c555",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "Bij het werken met een gridsearch is er nog een probleem omtrent data leakage.\n",
    "Omdat we in bovenstaande voorbeeld de scaling hebben gedaan op de volledige dataset is alle data in principe gebruikt om de scaling uit te voeren en dus gaat er steeds een effect zijn van de training-folds op de validation-fold wat niet gewenst is.\n",
    "Dit kan onterecht de score verbeteren.\n",
    "\n",
    "Om dit tegen te gaan kan men gebruik maken van Pipelines. Hiermee definieer je de flow die de data moet ondergaan om verwerkt te worden. De volledige pipeline of flow kan dan gegeven worden aan de gridsearch algoritme. Hierdoor worden de preprocessing stappen (zoals scalers, ordinal of one-hotencoder) steeds enkel op de training folds uitgevoerd.\n",
    "Dit zorgt ervoor dat er geen data leakage kan optreden. \n",
    "Het bijkomende voordeel is dat ook parameters van de preprocessing stappen meegenomen kunnen worden in de gridsearch.\n",
    "\n",
    "Let op dat NaN waarden invullen kan gebeuren in de pipeline maar rijen of kolommen weglaten kan niet gedaan worden tijdens de pipeline. Echter is het gebruik van een pipeline een goede stap in het verhogen van de leesbaarheid van een code stuk en wordt het daardoor veelvuldig gebruikt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42d7ac38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Zabour, Miss. Hileni</td>\n",
       "      <td>female</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2665</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>328.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Zabour, Miss. Thamine</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2665</td>\n",
       "      <td>14.4542</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Zakarian, Mr. Mapriededer</td>\n",
       "      <td>male</td>\n",
       "      <td>26.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2656</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>304.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Zakarian, Mr. Ortin</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2670</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Zimmerman, Mr. Leo</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>315082</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>None</td>\n",
       "      <td>S</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass                                             name     sex  \\\n",
       "0        1.0                    Allen, Miss. Elisabeth Walton  female   \n",
       "1        1.0                   Allison, Master. Hudson Trevor    male   \n",
       "2        1.0                     Allison, Miss. Helen Loraine  female   \n",
       "3        1.0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4        1.0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "...      ...                                              ...     ...   \n",
       "1304     3.0                             Zabour, Miss. Hileni  female   \n",
       "1305     3.0                            Zabour, Miss. Thamine  female   \n",
       "1306     3.0                        Zakarian, Mr. Mapriededer    male   \n",
       "1307     3.0                              Zakarian, Mr. Ortin    male   \n",
       "1308     3.0                               Zimmerman, Mr. Leo    male   \n",
       "\n",
       "          age  sibsp  parch  ticket      fare    cabin embarked  boat   body  \\\n",
       "0     29.0000    0.0    0.0   24160  211.3375       B5        S     2    NaN   \n",
       "1      0.9167    1.0    2.0  113781  151.5500  C22 C26        S    11    NaN   \n",
       "2      2.0000    1.0    2.0  113781  151.5500  C22 C26        S  None    NaN   \n",
       "3     30.0000    1.0    2.0  113781  151.5500  C22 C26        S  None  135.0   \n",
       "4     25.0000    1.0    2.0  113781  151.5500  C22 C26        S  None    NaN   \n",
       "...       ...    ...    ...     ...       ...      ...      ...   ...    ...   \n",
       "1304  14.5000    1.0    0.0    2665   14.4542     None        C  None  328.0   \n",
       "1305      NaN    1.0    0.0    2665   14.4542     None        C  None    NaN   \n",
       "1306  26.5000    0.0    0.0    2656    7.2250     None        C  None  304.0   \n",
       "1307  27.0000    0.0    0.0    2670    7.2250     None        C  None    NaN   \n",
       "1308  29.0000    0.0    0.0  315082    7.8750     None        S  None    NaN   \n",
       "\n",
       "                            home.dest  \n",
       "0                        St Louis, MO  \n",
       "1     Montreal, PQ / Chesterville, ON  \n",
       "2     Montreal, PQ / Chesterville, ON  \n",
       "3     Montreal, PQ / Chesterville, ON  \n",
       "4     Montreal, PQ / Chesterville, ON  \n",
       "...                               ...  \n",
       "1304                             None  \n",
       "1305                             None  \n",
       "1306                             None  \n",
       "1307                             None  \n",
       "1308                             None  \n",
       "\n",
       "[1309 rows x 13 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "X, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc271d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ nan, 135.,  22., 124., 148., 208., 172., 269.,  62., 133., 275.,\n",
       "       147., 110., 307.,  38.,  80.,  45., 258., 126., 292., 175., 249.,\n",
       "       230., 122., 263., 234., 189., 166., 207., 232.,  16., 109.,  96.,\n",
       "        46., 245., 169., 174.,  97.,  18., 130.,  17., 295., 286., 236.,\n",
       "       322., 297., 155., 305.,  19.,  75.,  35., 256., 149., 283., 165.,\n",
       "       108., 121.,  52., 209., 271.,  43.,  15., 101., 287.,  81., 294.,\n",
       "       293., 190.,  72., 103.,  79., 259., 260., 142., 299., 171.,   9.,\n",
       "       197.,  51., 187.,  68.,  47.,  98., 188.,  69., 306., 120., 143.,\n",
       "       156., 285.,  37.,  58.,  70., 196., 153.,  61.,  53., 201., 309.,\n",
       "       181., 173.,  89.,   4., 206., 327., 119.,   7.,  32.,  67., 284.,\n",
       "       261., 176.,  50.,   1., 255., 298., 314.,  14., 131., 312., 328.,\n",
       "       304.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.body.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f66da894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.7480916030534351\n"
     ]
    }
   ],
   "source": [
    "# verdeel de aanwezige kolommen in groepjes op basis van de data in de kolommen\n",
    "numeric_features = ['age', 'fare', 'body'] # body is een vorm van data leakage (lichaam gevonden en welk het is dus data die pas later gekend is)\n",
    "minmax_features = ['pclass', 'sibsp', 'parch'] # pclass is ordinal encoded, we willen dit enkel geschaald worden met behoud van de afstand\n",
    "categorical_features = ['sex', 'embarked'] # text naar getal\n",
    "dropped_features = ['name', 'ticket', 'cabin', 'boat', 'home.dest']\n",
    "\n",
    "# stel de pipelines op om elke soort kolom te verwerken\n",
    "pipeline_numeric = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')), # onbekende waarden invullen met waarden, want ML-technieken kunnen niet altijd goed omgaan met Null/Nan\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "pipeline_minmax= Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=-1)), # invullen met een niet voorkomende categorie\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "\n",
    "pipeline_categorical= Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')), # invullen met een niet voorkomende categorie\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# groepeer de preprocessors per soort kolom in een columntransformer\n",
    "# kolommen die niet in de columntransformer staan worden standaard niet doorgegeven (kan aangepast worden met de remainder parameter)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('numeric', pipeline_numeric, numeric_features),   # doe de pipeline_numeric voor de numeric_features\n",
    "        ('minmax', pipeline_minmax, minmax_features),\n",
    "        ('categorical', pipeline_categorical, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(solver='saga', max_iter=1000))\n",
    "])\n",
    "\n",
    "# best eerst X en y splitsen in train en test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print('model score:', clf.score(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d97af998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score: 0.7557251908396947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jens.baetens3\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "40 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jens.baetens3\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\jens.baetens3\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\jens.baetens3\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1101, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\jens.baetens3\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.7898716  0.7898716  0.7908258  0.7908258         nan        nan\n",
      " 0.79369205 0.7927342  0.79178366 0.79274151        nan        nan\n",
      " 0.79369205 0.7927342  0.79178731 0.79178366        nan        nan\n",
      " 0.79560045 0.79464625 0.79082946 0.79178366        nan        nan\n",
      " 0.79560045 0.79560411 0.79560045 0.79464625        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'classifier__penalty': ['l1', 'l2', 'elasticnet'],     # twee keer underscore tussen niveaus in de pipeline\n",
    "    'classifier__C': [0.1,0.6, 1, 1.4, 3],\n",
    "    'preprocessor__numeric__imputer__strategy': ['mean', 'median'] # pas de strategy parameter aan in de imputer van de numeric pipeline in de preprocessor\n",
    "}\n",
    "\n",
    "# param_grid kan ook een lijstje zijn van dictionaries.\n",
    "# elke set is een dictionary met opties die uitgevoerd worden zoals hierboven\n",
    "#param_grid = [\n",
    "#    set_1, set_2, set_3\n",
    "#]\n",
    "# dit is een mogelijkheid om opties te nemen die niet gecombineerd worden\n",
    "\n",
    "gridsearch = GridSearchCV(clf, param_grid, cv=4, scoring='accuracy')\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print('model score:', gridsearch.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d1af1d",
   "metadata": {},
   "source": [
    "## Oefening\n",
    "\n",
    "Maak een pipeline voor een gridsearch uit te voeren op de diabetes-dataset in sklearn. Gebruik een Min-Max scaler voor de numerieke waarden en een ordinal encoder voor de categorieke kolommen.\n",
    "Zoek naar de beste combinatie van hyperparameters van een SVM-classifier door middel van een grid search met cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d66e916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5e8e3a19af5ceb2434683dff87da6345c3b29f7eb0a8a138558c07d014a01cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
