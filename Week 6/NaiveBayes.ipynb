{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bea0993c",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "De Naive Bayes techniek is een **supervised** machine learning techniek voor **classificatie** problemen op te lossen.\n",
    "Dit is een redelijke oude techniek en wordt tegenwoordig al iets minder gebruikt.\n",
    "Echter is het een zeer snelle techniek, zelfs als er heel veel features zijn.\n",
    "Hierdoor is deze techniek wel nog nuttig in real-time toepassingen.\n",
    "\n",
    "Het verschil met de SVM of logistische regressie classifiers is dat dit een **Generative classifier** is in plaats van een Discriminatieve classifier.\n",
    "Een discriminatieve classifier is een classifier die de grens leer tussen twee verschillende klassen.\n",
    "Dit wil zeggen dat er een scheidingslijn gezocht wordt die geoptimaliseerd wordt op basis van misclassificaties.\n",
    "Bij discriminative wordt er dus vooral gekeken naar wat de klassen verschillend maakt.\n",
    "Een generative classifier echter gaat vooral kijken naar wat observaties van dezelfde klassen gemeenschappelijk hebben (welke features maken een observatie tot die klasse)\n",
    "Hierbij worden de verschillende features bekeken en er wordt gezocht naar een algemene verdeling van de observaties die tot elke klasse hoort. \n",
    "\n",
    "De benaming komt voort uit het feit dat Naive Bayes gebruikt maakt van de Bayes regel over conditionele probabiliteiten waarbij gebruik gemaakt wordt van de naieve veronderstelling dat de features onafhankelijk zijn van elkaar.\n",
    "\n",
    "## Werking: Bayes rule\n",
    "\n",
    "**Voorbeeld:**\n",
    "\n",
    "Kans dat je kanker hebt $1\\%$ ($P(Kanker) = 1\\% = 0.01$)\n",
    "\n",
    "Stel dat er een test is om kanker op te sporen die:\n",
    "* In 90% van de gevallen is de test positief als je kanker hebt (sensitiviteit)\n",
    "* In 90% van de gevallen is de test negatief als je geen kanker hebt (specificiteit)\n",
    "\n",
    "Wat is nu de kans dat je kanker hebt als deze test positief blijkt te zijn?\n",
    "\n",
    "Deze kans is niet 90% omdat er ook rekening gehouden moet worden met de kans dat iemand kanker heeft.\n",
    "We zijn dus echter op zoek naar $P(\\text{Kanker}|\\text{Positief})$.\n",
    "Door gebruik te maken van de Bayes regel kan dit uitgeschreven worden als volgt:\n",
    "\n",
    "$P(\\text{Kanker}|\\text{Positief}) = \\frac{P(\\text{Positief}|\\text{Kanker})P(\\text{Kanker})}{P(\\text{Positief})}$\n",
    "\n",
    "$P(\\text{Kanker}|\\text{Positief}) = \\frac{0.9 * 0.01}{0.01 * 0.9 + 0.1*0.99} = 0.08333$\n",
    "\n",
    "De verschillende kansen in deze uitdrukking hebben de volgende definities:\n",
    "* Prior: $P(\\text{Kanker})$: Kans dat iemand kanker heeft (zonder te testen)\n",
    "* Likelihood: $P(\\text{Positief}|\\text{Kanker})$: De kans dat je positief test als je kanker hebt\n",
    "* Marginal: $P(\\text{Positief})$: De kans dat je positief test\n",
    "* Posterior: $P(\\text{Kanker}|\\text{Positief})$: De kans dat je kanker hebt als je positief test\n",
    "\n",
    "De algemene vorm van bovenstaande berekening kan geschreven worden als\n",
    "\n",
    "$P(\\text{H}|\\text{e}) = \\frac{P(\\text{e}|\\text{H})P(\\text{H})}{P(\\text{e})}$\n",
    "\n",
    "waar: \n",
    "* e de evidence voorstelt (de features)\n",
    "* H de hypothese voorstelt (de features horen bij klasse $i$)\n",
    "\n",
    "Dit type classifier kan geimplementeerd worden door gebruik te maken van de [GaussianNB klasse](https://scikit-learn.org/stable/modules/naive_bayes.html) uit sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c98207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e844be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "wine = datasets.load_wine()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.2)\n",
    "\n",
    "naiveBayes = GaussianNB()\n",
    "naiveBayes.fit(X_train, y_train)\n",
    "y_pred = naiveBayes.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc18f26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
